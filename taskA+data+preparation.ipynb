{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from nltk.collocations import *\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import functools\n",
    "import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import product\n",
    "from __future__ import division\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk, string\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pymorphy2\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "# exclude = set(punctuation + u'0123456789[]—«»–')\n",
    "exclude = set(punctuation + u'[]—«»–')\n",
    "# import pylanguagetool\n",
    "import requests\n",
    "import json\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile(\"\"\"\n",
    "    (?:\n",
    "        (?:\n",
    "            (?<!\\\\d(?:р|г|к))\n",
    "            (?<!и\\\\.т\\\\.(?:д|п))\n",
    "            (?<!и(?=\\\\.т\\\\.(?:д|п)\\\\.))\n",
    "            (?<!и\\\\.т(?=\\\\.(?:д|п)\\\\.))\n",
    "            (?<!руб|коп)\n",
    "        \\\\.) |\n",
    "        [!?\\\\n]\n",
    "    )+\n",
    "    \"\"\", re.X)\n",
    "\n",
    "def safe_split(regex, text):\n",
    "    res = []\n",
    "    sear = regex.search(text)\n",
    "    while sear:\n",
    "        res.append(text[:sear.end()])\n",
    "        text = text[sear.end():]\n",
    "        sear = regex.search(text)\n",
    "    res.append(text)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_patterns(text):\n",
    "    tokens = text.split(' ')\n",
    "    return [[p.tag.POS for p in morph.parse(word)][0] for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_answer(text):\n",
    "    return ' '.join(re.findall(r\"\\w+\", text)).lower()\n",
    "\n",
    "def normalize_answer_no_lower(text):\n",
    "    return ' '.join(re.findall(r\"\\w+\", text))\n",
    "\n",
    "def sentence_to_word(sentences):\n",
    "    sentences_in_words = list()\n",
    "    for sentence in sentences:\n",
    "        sentences_in_words.append(normalize_answer(sentence).split())\n",
    "    return sentences_in_words\n",
    "\n",
    "def text_to_sentence(text):\n",
    "    sentences = safe_split(re1, text)\n",
    "    return [s.strip() for s in sentences if s.strip() != '']\n",
    "\n",
    "def get_max_match_sentance(data_row, w2v = False):\n",
    "    sentences = text_to_sentence(data_row[\"paragraph\"])\n",
    "    sentences_in_words = sentence_to_word(sentences)\n",
    "    question_in_words = sentence_to_word([data_row[\"question\"]])[0]\n",
    "    \n",
    "    max_overlap = None\n",
    "    max_match_sentance_id = None\n",
    "    \n",
    "    overlaps = []\n",
    "    question_words = set(question_in_words)\n",
    "    for sentance_id in range(len(sentences_in_words)):\n",
    "        sentence_words = set(sentences_in_words[sentance_id])\n",
    "        if w2v:\n",
    "            overlap = texts_intersection(sentences_in_words[sentance_id], question_in_words, model, 0.2)\n",
    "        else:\n",
    "            overlap = sentence_words.intersection(question_words)\n",
    "        overlaps.append(overlap)\n",
    "        \n",
    "        overlap_len = len(overlap)\n",
    "        if max_overlap is None or overlap_len > max_overlap:\n",
    "            max_overlap = overlap_len\n",
    "            max_match_sentance_id = sentance_id\n",
    "            \n",
    "    prediction_sentence = sentences[max_match_sentance_id]\n",
    "    prediction_words = ' '.join([x for x in prediction_sentence.split(' ') if x not in data_row[\"question\"].split(' ')])\n",
    "    question_residuals = ' '.join([x for x in data_row[\"question\"].split() if x not in prediction_sentence.split()])\n",
    "\n",
    "    return overlaps, prediction_sentence, prediction_words, question_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=2 ** 19)\n",
    "def uniq_words(text):\n",
    "    return set(re.findall(\"\\w+\", text))\n",
    "\n",
    "def calculate_idfs(data):\n",
    "    counter = Counter()\n",
    "    uniq_paragraphs = data['paragraph'].unique()\n",
    "    uniq_questions = data['question'].unique()\n",
    "    for paragraph in tqdm.tqdm(uniq_paragraphs, desc=\"calc idf for paragraph\"):\n",
    "        set_words = uniq_words(paragraph)\n",
    "        counter.update(set_words)\n",
    "    for question in tqdm.tqdm(uniq_questions, desc=\"calc idf for question\"):\n",
    "        set_words = uniq_words(question)\n",
    "        counter.update(set_words)\n",
    "    num_docs = uniq_paragraphs.shape[0] + uniq_questions.shape[0]\n",
    "    idfs = {}\n",
    "    for word in counter:\n",
    "        idfs[word] = np.log(num_docs / counter[word])\n",
    "    return idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    buf = ''.join(ch for ch in text if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(buf.lower())\n",
    "    lemmatizer = MorphAnalyzer()\n",
    "    lemmas = []\n",
    "    for t in tokens[:]:\n",
    "        if not t in stopwords.words('russian'):\n",
    "            try:\n",
    "                lemma = lemmatizer.parse(t)[0].normal_form\n",
    "            except: \n",
    "                lemma = t\n",
    "            lemmas.append(lemma)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texts_intersection(text1, text2, word2vec, threshold):\n",
    "    words1 = set(text1)\n",
    "    words2 = set(text2)\n",
    "    result = []\n",
    "    for word1 in words1:\n",
    "        for word2 in words2:\n",
    "            if word1 == word2:\n",
    "                similarity = 1.0\n",
    "            elif word1 in word2vec and word2 in word2vec:\n",
    "                similarity = word2vec.similarity(word1, word2)\n",
    "            else:\n",
    "                similarity = 0.0\n",
    "            if similarity >= threshold:\n",
    "                result.append(word1)\n",
    "                result.append(word2)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = ['ADJF+NOUN','PRTS+NOUN','NOUN+NOUN', 'NOUN+VERB', 'VERB+ADJF', 'VERB+NOUN']\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def match(ngram, patterns = patterns):\n",
    "    index = []\n",
    "    for word in ngram:\n",
    "        buf = [(p.normal_form, p.tag.POS) for p in morph.parse(word)]\n",
    "        index.append((word,buf))\n",
    "    pos_tagging = product(*[ind[1] for ind in index])\n",
    "    possible_patterns = map(lambda pos_tag: list(zip(*pos_tag)), pos_tagging)\n",
    "    possible_patterns = map(lambda pattern: [pattern[0], map(lambda grammeme: grammeme, pattern[1])], possible_patterns)\n",
    "    possible_patterns = map(lambda pattern: (pattern[0], '+'.join(pattern[1])), possible_patterns)\n",
    "    for pattern in possible_patterns:\n",
    "        if pattern[1] in patterns:\n",
    "            return pattern\n",
    "    return None        \n",
    "\n",
    "def get_pattern(text):\n",
    "    tokens = [x for x in normalize(text)]\n",
    "    pattern_coll2  = nltk.FreqDist() \n",
    "    coll2 = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "    for c2 in coll2:\n",
    "        try:\n",
    "            p = match(c2)\n",
    "            if p != None:\n",
    "                collocation = ' '.join(p[0])\n",
    "                if collocation in pattern_coll2:\n",
    "                    pattern_coll2[collocation] += coll2[c2]\n",
    "                else:\n",
    "                    pattern_coll2[collocation] = coll2[c2]\n",
    "        except:\n",
    "            pass\n",
    "    return pattern_coll2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "372\t27273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66135</th>\n",
       "      <td>372</td>\n",
       "      <td>27273</td>\n",
       "      <td>Международный арбитражный суд при Международной торговой палате (англ. International Court of Arbitration of the International Chamber of Commerce) — международный суд, разрешающий арбитражные коммерческие споры. Основан в 1923 году, министром финансов Франции Этьеном Клементелем. Выступает в роли третейского посредника в разрешении споров. Решения суда не имеют обязательной силы. Формирование состава суда происходит по общему правилу третейских судов. Наиболее известный и опытный среди международных арбитражных институтов.</td>\n",
       "      <td>Как происходит формирование состава суда?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraph_id  question_id  \\\n",
       "66135           372        27273   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               paragraph  \\\n",
       "66135  Международный арбитражный суд при Международной торговой палате (англ. International Court of Arbitration of the International Chamber of Commerce) — международный суд, разрешающий арбитражные коммерческие споры. Основан в 1923 году, министром финансов Франции Этьеном Клементелем. Выступает в роли третейского посредника в разрешении споров. Решения суда не имеют обязательной силы. Формирование состава суда происходит по общему правилу третейских судов. Наиболее известный и опытный среди международных арбитражных институтов.   \n",
       "\n",
       "                                        question  \n",
       "66135  Как происходит формирование состава суда?  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/sdsj_A_test.csv\")\n",
    "df[df['paragraph_id'] == 372][df['question_id'] == 27273]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftrain, dftest = pd.read_csv(\"../../data/train_task1_latest.csv\"), pd.read_csv(\"../../data/sdsj_A_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # add pattern generated questions\n",
    "# dftrain_generated = pd.read_csv(\"../../data/taskA_generated_questions_p.csv\", sep=';')\n",
    "# dftrain_generated = dftrain_generated.sample(5000)\n",
    "# question_id = np.max([dftrain.question_id.max(), dftest.question_id.max()]) + 1\n",
    "# for row in dftrain_generated.iterrows():\n",
    "#     dftrain_generated.loc[row[0], 'question_id'] = question_id\n",
    "#     question_id += 1\n",
    "# dftrain_generated['target'] = 0.0\n",
    "# dftrain_generated['generated_p'] = 1.0\n",
    "# dftrain_generated.columns = ['paragraph_id', 'paragraph', 'question', 'question_id', 'target', 'generated_p']\n",
    "# dftrain['generated_p'] = 0.0\n",
    "# dftrain = dftrain.append(dftrain_generated, ignore_index=True)\n",
    "# dftrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # add pattern_2 generated questions\n",
    "# dftrain_generated = pd.read_csv(\"../../data/taskA_generated_questions_p_2.csv\", sep=';')\n",
    "# dftrain_generated = dftrain_generated.sample(5000)\n",
    "# question_id = np.max([dftrain.question_id.max(), dftest.question_id.max()]) + 1\n",
    "# for row in dftrain_generated.iterrows():\n",
    "#     dftrain_generated.loc[row[0], 'question_id'] = question_id\n",
    "#     question_id += 1\n",
    "# dftrain_generated['target'] = 0.0\n",
    "# dftrain_generated['generated_p_2'] = 1.0\n",
    "# dftrain_generated.columns = ['paragraph_id', 'paragraph', 'question', 'question_id', 'target', 'generated_p_2']\n",
    "# dftrain['generated_p_2'] = 0.0\n",
    "# dftrain = dftrain.append(dftrain_generated, ignore_index=True)\n",
    "# dftrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add pattern_3 generated questions\n",
    "dftrain_generated = pd.read_csv(\"../../data/taskA_generated_questions_p_3.csv\", sep=';')\n",
    "dftrain_generated = dftrain_generated.sample(20000)\n",
    "question_id = np.max([dftrain.question_id.max(), dftest.question_id.max()]) + 1\n",
    "for row in dftrain_generated.iterrows():\n",
    "    dftrain_generated.loc[row[0], 'question_id'] = question_id\n",
    "    question_id += 1\n",
    "dftrain_generated['target'] = 0.0\n",
    "dftrain_generated['generated_p_3'] = 1.0\n",
    "dftrain_generated.columns = ['paragraph_id', 'paragraph', 'question', 'question_id', 'target', 'generated_p_3']\n",
    "dftrain['generated_p_3'] = 0.0\n",
    "dftrain = dftrain.append(dftrain_generated, ignore_index=True)\n",
    "dftrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # add pattern_4 generated questions\n",
    "# dftrain_generated = pd.read_csv(\"../../data/taskA_generated_questions_p_4.csv\", sep=';')\n",
    "# dftrain_generated = dftrain_generated.sample(5000)\n",
    "# question_id = np.max([dftrain.question_id.max(), dftest.question_id.max()]) + 1\n",
    "# for row in dftrain_generated.iterrows():\n",
    "#     dftrain_generated.loc[row[0], 'question_id'] = question_id\n",
    "#     question_id += 1\n",
    "# dftrain_generated['target'] = 0.0\n",
    "# dftrain_generated['generated_p_4'] = 1.0\n",
    "# dftrain_generated.columns = ['paragraph_id', 'paragraph', 'question', 'question_id', 'target', 'generated_p_4']\n",
    "# dftrain['generated_p_4'] = 0.0\n",
    "# dftrain = dftrain.append(dftrain_generated, ignore_index=True)\n",
    "# dftrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add pattern_6 generated questions\n",
    "dftrain_generated = pd.read_csv(\"../../data/taskA_generated_questions_p_6.csv\", sep=';')\n",
    "dftrain_generated = dftrain_generated\n",
    "question_id = np.max([dftrain.question_id.max(), dftest.question_id.max()]) + 1\n",
    "for row in dftrain_generated.iterrows():\n",
    "    dftrain_generated.loc[row[0], 'question_id'] = question_id\n",
    "    question_id += 1\n",
    "dftrain_generated['target'] = 0.0\n",
    "dftrain_generated['generated_p_6'] = 1.0\n",
    "dftrain_generated.columns = ['paragraph_id', 'paragraph', 'question', 'question_id', 'target', 'generated_p_6']\n",
    "dftrain['generated_p_6'] = 0.0\n",
    "dftrain = dftrain.append(dftrain_generated, ignore_index=True)\n",
    "dftrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calc idf for paragraph: 100%|██████████| 10705/10705 [00:00<00:00, 38029.69it/s]\n",
      "calc idf for question: 100%|██████████| 122193/122193 [00:01<00:00, 63552.35it/s]\n"
     ]
    }
   ],
   "source": [
    "idfs = calculate_idfs(dftrain.append(dftest, ignore_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build features for train: 100%|██████████| 159391/159391 [13:15<00:00, 200.25it/s]\n",
      "build features for test: 100%|██████████| 74286/74286 [04:49<00:00, 256.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"build features for \" + name):\n",
    "        question = uniq_words(row.question)\n",
    "        paragraph = uniq_words(row.paragraph)\n",
    "        df.loc[index, 'len_paragraph'] = len(paragraph)\n",
    "        df.loc[index, 'len_question'] = len(question)\n",
    "        df.loc[index, 'len_intersection'] = len(paragraph & question)\n",
    "        df.loc[index, 'idf_question'] = np.sum([idfs.get(word, 0.0) for word in question])\n",
    "        df.loc[index, 'idf_paragraph'] = np.sum([idfs.get(word, 0.0) for word in paragraph])\n",
    "        df.loc[index, 'idf_intersection'] = np.sum([idfs.get(word, 0.0) for word in paragraph & question])\n",
    "        \n",
    "    df['relative_question_len'] = df['len_question'] / df['len_paragraph']\n",
    "    df['relative_intersection_len'] = df['len_intersection'] / df['len_paragraph']\n",
    "    df['relative_intersection_question_len'] = df['len_intersection'] / df['len_question']\n",
    "    \n",
    "    df['relative_question_idf'] = df['idf_question'] / df['idf_paragraph']\n",
    "    df['relative_intersection_idf'] = df['idf_intersection'] / df['idf_paragraph']\n",
    "    df['relative_intersection_question_idf'] = df['idf_intersection'] / df['idf_question']\n",
    "    \n",
    "    df['word_idf_paragraph'] = df['idf_paragraph'] / df['len_paragraph']\n",
    "    df['word_idf_question'] = df['idf_question'] / df['len_question']\n",
    "    df['word_idf_intersection'] = df['idf_intersection'] / df['len_intersection'] \n",
    "    \n",
    "    df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data mining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lemmarize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftrain complete - paragraph_lemmatized\n",
      "dftrain complete - question_lemmatized\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train - paragraph\n",
    "df = pd.DataFrame(dftrain.paragraph.unique())\n",
    "df.columns = ['paragraph']\n",
    "df['paragraph_lemmatized'] = df['paragraph'].map(lambda x: preprocess(x))\n",
    "dftrain = dftrain.merge(df, on = 'paragraph', how = 'left')\n",
    "print('dftrain complete - paragraph_lemmatized')\n",
    "\n",
    "# train - question\n",
    "df = pd.DataFrame(dftrain.question.unique())\n",
    "df.columns = ['question']\n",
    "df['question_lemmatized'] = df['question'].map(lambda x: preprocess(x))\n",
    "dftrain = dftrain.merge(df, on = 'question', how = 'left')\n",
    "print('dftrain complete - question_lemmatized')\n",
    "\n",
    "# test - paragraph\n",
    "df = pd.DataFrame(dftest.paragraph.unique())\n",
    "df.columns = ['paragraph']\n",
    "df['paragraph_lemmatized'] = df['paragraph'].map(lambda x: preprocess(x))\n",
    "dftest = dftest.merge(df, on = 'paragraph', how = 'left')\n",
    "print('dftest complete - paragraph_lemmatized')\n",
    "\n",
    "# test - question\n",
    "df = pd.DataFrame(dftest.question.unique())\n",
    "df.columns = ['question']\n",
    "df['question_lemmatized'] = df['question'].map(lambda x: preprocess(x))\n",
    "dftest = dftest.merge(df, on = 'question', how = 'left')\n",
    "print('dftest complete - question_lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"../../data/ruwikiruscorpora_0_300_20.bin.gz\", binary=True)\n",
    "new_vocab = {}\n",
    "[new_vocab.update({k[0].replace(\"::\", \"_\").split('_')[0]: k[1]}) for k in model.vocab.items()]\n",
    "model.vocab = new_vocab\n",
    "\n",
    "# or build model\n",
    "\n",
    "# model = word2vec.Word2Vec(np.append(dftrain.paragraph_lemmatized, \n",
    "#                                     np.append(dftrain[dftrain.generated_p_2 ==0][dftrain.generated_p ==0].question_lemmatized, \n",
    "#                                               dftest.paragraph_lemmatized)),\n",
    "#                  size=100, \n",
    "#                  window=5, \n",
    "#                  min_count=5, \n",
    "#                  workers=4)\n",
    "# fname = '../results/word2vec_model'\n",
    "# model.save(fname)\n",
    "# # model = word2vec.Word2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word2vec\"):  \n",
    "        question = row['question_lemmatized']\n",
    "        paragraph = row['paragraph_lemmatized']\n",
    "        w2v_similarities = []\n",
    "        for question_word in question.split(' '):\n",
    "            max_similarity = 0.0\n",
    "            for paragraph_word in paragraph.split(' '):\n",
    "                if (question_word in model.wv.vocab) and (paragraph_word in model.wv.vocab):\n",
    "                    similarity = model.similarity(question_word, paragraph_word)\n",
    "                    if similarity > max_similarity:\n",
    "                        max_similarity = similarity\n",
    "            w2v_similarities.append(max_similarity)\n",
    "#         w2v_similarities = [x for x in w2v_similarities if x > 0.2]\n",
    "        \n",
    "        if len(w2v_similarities) == 0:\n",
    "            df.loc[index, 'word2vec_similarity_max'] = 0\n",
    "            df.loc[index, 'word2vec_similarity_min'] = 0\n",
    "        else:\n",
    "            df.loc[index, 'word2vec_similarity_max'] = np.max(w2v_similarities)\n",
    "            df.loc[index, 'word2vec_similarity_min'] = np.min(w2v_similarities)\n",
    "        df.loc[index, 'word2vec_similarity_mean'] = np.mean(w2v_similarities)\n",
    "        df.loc[index, 'word2vec_similarity_std'] = np.std(w2v_similarities)\n",
    "    df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"build features for \" + name):\n",
    "        intersection = texts_intersection(row.paragraph_lemmatized.split(' '), row.question_lemmatized.split(' '), model, 0.2)\n",
    "        df.loc[index, 'len_intersection_w2v'] = len(intersection) / 2.0\n",
    "        df.loc[index, 'idf_intersection_w2v'] = np.sum([idfs.get(word, 0.0) for word in intersection]) / 2.0\n",
    "    df['relative_intersection_len_w2v'] = df['len_intersection_w2v'] / df['len_paragraph']\n",
    "    df['relative_intersection_question_len_w2v'] = df['len_intersection_w2v'] / df['len_question']\n",
    "    df['relative_intersection_idf_w2v'] = df['idf_intersection_w2v'] / df['idf_paragraph']\n",
    "    df['relative_intersection_question_idf_w2v'] = df['idf_intersection_w2v'] / df['idf_question']\n",
    "    df['word_idf_intersection_w2v'] = df['idf_intersection_w2v'] / df['len_intersection'] \n",
    "    df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word mover distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word mover distance for \" + name):\n",
    "        df.loc[index, 'word_mover_distance'] = model.wmdistance(row['paragraph'], row['question'])\n",
    "        df.loc[index, 'word_mover_distance_lemm'] = model.wmdistance(row['paragraph_lemmatized'], row['question_lemmatized'])\n",
    "        \n",
    "        wmds = []\n",
    "        for paragraph_sentence in text_to_sentence(row['paragraph']):\n",
    "            wmds.append(model.wmdistance(paragraph_sentence, row['question']))\n",
    "            \n",
    "        df.loc[index, 'word_mover_sentence_distance_mean'] = np.mean(wmds)\n",
    "        df.loc[index, 'word_mover_sentence_distance_std'] = np.std(wmds)\n",
    "        df.loc[index, 'word_mover_sentence_distance_max'] = np.max(wmds)\n",
    "        df.loc[index, 'word_mover_sentence_distance_min'] = np.min(wmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word mover distance for \" + name):\n",
    "        question = row.question\n",
    "        question_lemm = row.question_lemmatized\n",
    "        question_len = len(question_lemm)\n",
    "        similarities = []\n",
    "        similarities_lemm = []\n",
    "        if int(question_len / 3) != 0:\n",
    "            for i in range(0, question_len, int(question_len / 3)):\n",
    "                question_chunk = question[i:i + int(question_len / 3)]\n",
    "                similarities.append(model.wmdistance(question_chunk, row['paragraph']))\n",
    "                question_chunk_lemm = question_lemm[i:i + int(question_len / 3)]\n",
    "                similarities_lemm.append(model.wmdistance(question_chunk_lemm, row['paragraph_lemmatized']))\n",
    "        elif int(question_len / 2) != 0:\n",
    "            for i in range(0, question_len, int(question_len / 2)):\n",
    "                question_chunk = question[i:i + int(question_len / 2)]\n",
    "                similarities.append(model.wmdistance(question_chunk, row['paragraph']))\n",
    "                question_chunk_lemm = question_lemm[i:i + int(question_len / 2)]\n",
    "                similarities_lemm.append(model.wmdistance(question_chunk_lemm, row['paragraph_lemmatized']))\n",
    "        else:\n",
    "            question_chunk = question\n",
    "            similarities.append(model.wmdistance(question_chunk, row['paragraph']))\n",
    "            question_chunk_lemm = question_lemm\n",
    "            similarities_lemm.append(model.wmdistance(question_chunk_lemm, row['paragraph_lemmatized']))\n",
    "            \n",
    "        df.loc[index, 'word_mover_sentence_distance_split_max'] = np.max(similarities)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_min'] = np.min(similarities)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_mean'] = np.mean(similarities)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_std'] = np.std(similarities)\n",
    "        \n",
    "        df.loc[index, 'word_mover_sentence_distance_split_lemm_max'] = np.max(similarities_lemm)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_lemm_min'] = np.min(similarities_lemm)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_lemm_mean'] = np.mean(similarities_lemm)\n",
    "        df.loc[index, 'word_mover_sentence_distance_split_lemm_std'] = np.std(similarities_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max match sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating max overlap: 100%|██████████| 159391/159391 [2:11:25<00:00, 20.21it/s] \n",
      "calculating max overlap: 100%|██████████| 74286/74286 [37:57<00:00, 29.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating max overlap\"):        \n",
    "        overlaps, prediction_sentence, answer, question_residuals = get_max_match_sentance(row)\n",
    "        \n",
    "        # vars\n",
    "        a = [len(x) / len(row['paragraph']) for x in overlaps]\n",
    "        b = [len(x) / len(row['question']) for x in overlaps]\n",
    "        c = [np.sum([idfs.get(word, 0.0) for word in overlap]) for overlap in overlaps]\n",
    "        \n",
    "        # answer \n",
    "        df.loc[index, 'answer'] = answer\n",
    "        \n",
    "        # prediction_sentence\n",
    "        df.loc[index, 'prediction_sentence'] = prediction_sentence\n",
    "        \n",
    "        # answer len\n",
    "        answer_len = len(answer.split(' '))\n",
    "        df.loc[index, 'answer_len'] = answer_len\n",
    "        if len(row.question) != 0:\n",
    "            df.loc[index, 'answer_len_relative_question'] = answer_len / len(row.question)\n",
    "        if len(prediction_sentence) != 0:\n",
    "            df.loc[index, 'answer_len_relative_prediction_sentence'] = answer_len / len(prediction_sentence)\n",
    "        \n",
    "        # answer idf\n",
    "        answer_idf = np.sum([idfs.get(word, 0.0) for word in answer.split(' ')])\n",
    "        df.loc[index, 'answer_idf'] = answer_idf \n",
    "        df.loc[index, 'answer_idf_relative_question'] = answer_idf / np.sum([idfs.get(word, 0.0) for word in row.question.split(' ')])\n",
    "        df.loc[index, 'answer_idf_relative_prediction_sentence'] = answer_idf / np.sum([idfs.get(word, 0.0) for word in prediction_sentence.split(' ')])\n",
    "        \n",
    "        # residuals\n",
    "        df.loc[index, 'question_residuals'] = question_residuals\n",
    "        \n",
    "        # residuals len\n",
    "        question_residuals_len = len(question_residuals.split(' '))\n",
    "        df.loc[index, 'question_residuals_len'] = question_residuals_len\n",
    "        if len(row.question) != 0:\n",
    "            df.loc[index, 'question_residuals_len_relative_question'] = question_residuals_len / len(row.question)\n",
    "        if len(prediction_sentence) != 0:\n",
    "            df.loc[index, 'question_residuals_len_relative_prediction_sentence'] = question_residuals_len / len(prediction_sentence)\n",
    "            \n",
    "        # residuals idf\n",
    "        question_residuals_idf = np.sum([idfs.get(word, 0.0) for word in question_residuals.split(' ')])\n",
    "        df.loc[index, 'question_residuals_idf'] = question_residuals_idf \n",
    "        df.loc[index, 'question_residuals_idf_relative_question'] = question_residuals_idf / np.sum([idfs.get(word, 0.0) for word in row.question.split(' ')])\n",
    "        df.loc[index, 'question_residuals_idf_relative_prediction_sentence'] = question_residuals_idf / np.sum([idfs.get(word, 0.0) for word in prediction_sentence.split(' ')])\n",
    "        \n",
    "        # max\n",
    "        max_overlap = ''\n",
    "        max_overlap_idf = 0\n",
    "        for overlap in overlaps:\n",
    "            overlap_idf = np.sum([idfs.get(word, 0.0) for word in overlap])\n",
    "            if overlap_idf > max_overlap_idf:\n",
    "                max_overlap_idf = overlap_idf\n",
    "                max_overlap = overlap\n",
    "        df.loc[index, 'overlap'] = ' '.join(max_overlap)\n",
    "        \n",
    "        df.loc[index, 'len_overlap_relative_paragraph_max'] = np.max(a)\n",
    "        df.loc[index, 'len_overlap_relative_question_max'] = np.max(b)\n",
    "        df.loc[index, 'idf_overlap_max'] = np.max(c)\n",
    "        \n",
    "        # means\n",
    "        df.loc[index, 'len_overlap_relative_paragraph_mean'] = np.mean(a)\n",
    "        df.loc[index, 'len_overlap_relative_question_mean'] = np.mean(b)\n",
    "        df.loc[index, 'idf_overlap_mean'] = np.mean(c)\n",
    "        \n",
    "        # stds\n",
    "        df.loc[index, 'len_overlap_relative_paragraph_std'] = np.std(a)\n",
    "        df.loc[index, 'len_overlap_relative_question_std'] = np.std(b)\n",
    "        df.loc[index, 'idf_overlap_std'] = np.std(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "vectorizer.fit(set(np.append(pd.unique([x for x in dftrain.paragraph_lemmatized.values]),\n",
    "                                     np.append(pd.unique([x for x in dftrain[dftrain.generated_p_3 ==0][dftrain.generated_p_6 ==0].question_lemmatized.values]),\n",
    "                                              pd.unique([x for x in dftest.paragraph_lemmatized.values])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating nlps for train: 100%|██████████| 159391/159391 [20:15<00:00, 131.13it/s]\n",
      "calculating nlps for test: 100%|██████████| 74286/74286 [08:33<00:00, 144.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate cummulative nlpS\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating nlps for \" + name):\n",
    "        vectors = vectorizer.transform([row.paragraph_lemmatized, row.question_lemmatized])\n",
    "        df.loc[index, 'similarity_tfid'] = (vectors * vectors.T)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating word mover distance for train: 100%|██████████| 159391/159391 [10:55<00:00, 243.32it/s]\n",
      "calculating word mover distance for test: 100%|██████████| 74286/74286 [05:07<00:00, 241.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# word mover distance prediction\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word mover distance for \" + name):\n",
    "        df.loc[index, 'word_mover_distance_prediction'] = model.wmdistance(row['prediction_sentence'], row['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # calculate similarity between prediction sentence and question \n",
    "# for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "#     for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating nlps for \" + name):\n",
    "#         vectors = vectorizer.transform([row.prediction_sentence, row.question])\n",
    "#         df.loc[index, 'similarity_prediction_tfid'] = (vectors * vectors.T)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating word mover distance for train: 100%|██████████| 159391/159391 [13:42<00:00, 193.80it/s]\n",
      "calculating word mover distance for test: 100%|██████████| 74286/74286 [07:01<00:00, 176.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# word mover distance residuals\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word mover distance for \" + name):\n",
    "        df.loc[index, 'word_mover_distance_residuals'] = model.wmdistance(row['question_residuals'], row['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating word mover distance for train: 100%|██████████| 159391/159391 [09:57<00:00, 266.75it/s]\n",
      "calculating word mover distance for test: 100%|██████████| 74286/74286 [04:45<00:00, 260.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# word mover distance residuals\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating word mover distance for \" + name):\n",
    "        df.loc[index, 'word_mover_distance_residuals_prediction'] = model.wmdistance(row['question_residuals'], row['prediction_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "#     df['similarity_difference'] = df['similarity_tfid'] - df['similarity ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # calculate similarity between prediction sentence and question \n",
    "# for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "#     for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating nlps for \" + name):\n",
    "#         vectors = vectorizer.transform([row.question_residuals, row.paragraph])\n",
    "#         df.loc[index, 'similarity_residuals_tfid'] = (vectors * vectors.T)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating nlps for train: 100%|██████████| 159391/159391 [1:13:16<00:00, 39.42it/s]\n",
      "calculating nlps for test: 100%|██████████| 74286/74286 [29:39<00:00, 41.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate cummulative nlpS - split question to chunks\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"calculating nlps for \" + name):\n",
    "        question = row.question_lemmatized\n",
    "        question_str = question\n",
    "        question_len = len(question_str)\n",
    "        similarities = []\n",
    "        if int(question_len / 3) != 0:\n",
    "            for i in range(0, question_len, int(question_len / 3)):\n",
    "                question_chunk = question[i:i + int(question_len / 3)]\n",
    "                vectors = vectorizer.transform([row.paragraph_lemmatized, question_chunk])\n",
    "                similarities.append((vectors * vectors.T)[0, 1])\n",
    "        elif int(question_len / 2) != 0:\n",
    "            for i in range(0, question_len, int(question_len / 2)):\n",
    "                question_chunk = question[i:i + int(question_len / 2)]\n",
    "                vectors = vectorizer.transform([row.paragraph_lemmatized, question_chunk])\n",
    "                similarities.append((vectors * vectors.T)[0, 1])\n",
    "        else:\n",
    "            question_chunk = question\n",
    "            vectors = vectorizer.transform([row.paragraph_lemmatized, question_chunk])\n",
    "            similarities.append((vectors * vectors.T)[0, 1])\n",
    "        df.loc[index, 'similarity_tfid_split_max'] = np.max(similarities)\n",
    "        df.loc[index, 'similarity_tfid_split_min'] = np.min(similarities)\n",
    "        df.loc[index, 'similarity_tfid_split_mean'] = np.mean(similarities)\n",
    "        df.loc[index, 'similarity_tfid_split_std'] = np.std(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**словосочетания**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grammar for train:   9%|▉         | 14692/159391 [28:35<4:19:53,  9.28it/s] "
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"grammar for \" + name):\n",
    "        question_patterns = list(get_pattern(row.question).keys())\n",
    "        paragraph_patterns = list(get_pattern(row.paragraph).keys())\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "        vectorizer.fit(np.append(question_patterns, paragraph_patterns))\n",
    "        similarity_pattern = []\n",
    "        for pattern in question_patterns:\n",
    "            vectors = vectorizer.transform(np.append(pattern, paragraph_patterns))\n",
    "            # eliminate diagonal 1'ses\n",
    "            matrix = (vectors * vectors.T)\n",
    "            n = matrix.shape[0]\n",
    "            matrix[range(n), range(n)] = 0\n",
    "            similarity_pattern.append(matrix[0].max())\n",
    "        # get max similarity\n",
    "        df.loc[index, 'similarity_pattern_mean'] = np.mean(similarity_pattern)\n",
    "        df.loc[index, 'similarity_pattern_std'] = np.std(similarity_pattern)\n",
    "        if len(similarity_pattern) == 0:\n",
    "            df.loc[index, 'similarity_pattern_max'] = 0\n",
    "            df.loc[index, 'similarity_pattern_min'] = 0\n",
    "        else:\n",
    "            df.loc[index, 'similarity_pattern_max'] = np.max(similarity_pattern)\n",
    "            df.loc[index, 'similarity_pattern_min'] = np.min(similarity_pattern)\n",
    "    df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grammar for train: 100%|██████████| 159391/159391 [11:27<00:00, 231.69it/s]\n",
      "grammar for test: 100%|██████████| 74286/74286 [04:14<00:00, 292.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"grammar for \" + name):\n",
    "        question_lemmatized = row.question_lemmatized\n",
    "        \n",
    "        unique_words_len = len(set(question_lemmatized))\n",
    "        df.loc[index, 'unique_words_relative_to_question'] = unique_words_len / row.len_question\n",
    "        \n",
    "        word_occurences = []\n",
    "        for word in question_lemmatized.split(' '):\n",
    "            word_occurences.append(question_lemmatized.count(word))\n",
    "            \n",
    "        df.loc[index, 'word_ocurences_mean'] = np.mean(word_occurences)\n",
    "        df.loc[index, 'word_ocurences_std'] = np.std(word_occurences)\n",
    "        df.loc[index, 'word_ocurences_max'] = np.max(word_occurences)\n",
    "        df.loc[index, 'word_ocurences_max_relative_to_question'] = np.max(word_occurences) / row.len_question\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ручные правила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question_types_keys = ['кто', 'кого', 'когда', 'почему', 'зачем', 'отчего', 'куда', 'кому', 'чему', 'как', 'о ком', 'чем',\n",
    "                  'на чем', 'как', 'сколько', 'где', 'какого', 'откуда', 'чего', 'кем', 'чем', 'чей', 'который', 'какой',\n",
    "                  'какая', 'какие', 'какое', 'каких', 'какие', 'чья', 'чьи', 'чье']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grammar for train: 100%|██████████| 159391/159391 [02:43<00:00, 975.89it/s] \n",
      "grammar for test: 100%|██████████| 74286/74286 [01:03<00:00, 1163.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"grammar for \" + name):\n",
    "        \n",
    "        question_words = row.question.lower().strip('?').split(' ')\n",
    "        paragraph_words = row.paragraph.lower().replace('.', '').split(' ')\n",
    "        \n",
    "        count = 0\n",
    "        for word in question_words:\n",
    "            if word in paragraph_words:\n",
    "                count += 1\n",
    "                \n",
    "        df.loc[index, 'question_words_in_paragraph_relative'] = count / len(question_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grammar for train: 100%|██████████| 159391/159391 [19:25<00:00, 136.79it/s]\n",
      "grammar for test: 100%|██████████| 74286/74286 [06:23<00:00, 193.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# relative siimlarities\n",
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"grammar for \" + name):\n",
    "        \n",
    "        similarity_tfid = row.similarity_tfid\n",
    "        similarity_tfid_split_mean = row.similarity_tfid_split_mean\n",
    "        similarity_pattern_mean = row.similarity_pattern_mean\n",
    "        \n",
    "        word_mover_distance = row.word_mover_distance\n",
    "        word_mover_sentence_distance_mean = row.word_mover_sentence_distance_mean\n",
    "        word_mover_sentence_distance_split_mean = row.word_mover_sentence_distance_split_mean\n",
    "        word_mover_sentence_distance_split_lemm_mean = row.word_mover_sentence_distance_split_lemm_mean\n",
    "        word_mover_distance_residuals = row.word_mover_distance_residuals\n",
    "        word_mover_distance_residuals_prediction = row.word_mover_distance_residuals_prediction\n",
    "        \n",
    "        df.loc[index, 'similarity_all_mean'] = np.mean([similarity_tfid, similarity_tfid_split_mean, similarity_pattern_mean])\n",
    "        \n",
    "        if similarity_tfid_split_mean != 0:\n",
    "            df.loc[index, 'similarity_tfid_relative_split'] = similarity_tfid / similarity_tfid_split_mean\n",
    "        else:\n",
    "            df.loc[index, 'similarity_tfid_relative_split'] = 0\n",
    "            \n",
    "        if similarity_pattern_mean != 0:\n",
    "            df.loc[index, 'similarity_tfid_relative_pattern'] = similarity_tfid / similarity_pattern_mean\n",
    "        else:\n",
    "            df.loc[index, 'similarity_tfid_relative_pattern'] = 0\n",
    "            \n",
    "        # w2v\n",
    "        df.loc[index, 'word_mover_distance_all_mean'] = np.mean([word_mover_distance, \n",
    "                                                                word_mover_sentence_distance_mean, \n",
    "                                                               word_mover_sentence_distance_split_mean,\n",
    "                                                               word_mover_sentence_distance_split_lemm_mean])\n",
    "        df.loc[index, 'word_mover_distance_all_mean_all'] = np.mean([word_mover_distance, \n",
    "                                                                word_mover_sentence_distance_mean, \n",
    "                                                               word_mover_sentence_distance_split_mean,\n",
    "                                                               word_mover_sentence_distance_split_lemm_mean,\n",
    "                                                                   word_mover_distance_residuals,\n",
    "                                                                   word_mover_distance_residuals_prediction])\n",
    "        \n",
    "        if word_mover_sentence_distance_mean != 0:\n",
    "            df.loc[index, 'word_mover_distance_relative_sentence'] = word_mover_distance / word_mover_sentence_distance_mean\n",
    "        else:\n",
    "            df.loc[index, 'word_mover_distance_relative_sentence'] = 0\n",
    "            \n",
    "        if word_mover_sentence_distance_split_mean != 0:\n",
    "            df.loc[index, 'word_mover_distance_relative_sentence_split'] = word_mover_distance / word_mover_sentence_distance_split_mean\n",
    "        else:\n",
    "            df.loc[index, 'word_mover_distance_relative_sentence_split'] = 0\n",
    "            \n",
    "        if word_mover_distance_residuals_prediction != 0:\n",
    "            df.loc[index, 'word_mover_distance_residuals_relative_paragraph'] = word_mover_distance_residuals / word_mover_distance_residuals_prediction\n",
    "        else:\n",
    "            df.loc[index, 'word_mover_distance_residuals_relative_paragraph'] = 0\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_p_3</th>\n",
       "      <th>generated_p_6</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>target</th>\n",
       "      <th>len_paragraph</th>\n",
       "      <th>len_question</th>\n",
       "      <th>len_intersection</th>\n",
       "      <th>idf_question</th>\n",
       "      <th>idf_paragraph</th>\n",
       "      <th>idf_intersection</th>\n",
       "      <th>relative_question_len</th>\n",
       "      <th>relative_intersection_len</th>\n",
       "      <th>relative_intersection_question_len</th>\n",
       "      <th>relative_question_idf</th>\n",
       "      <th>relative_intersection_idf</th>\n",
       "      <th>relative_intersection_question_idf</th>\n",
       "      <th>word_idf_paragraph</th>\n",
       "      <th>word_idf_question</th>\n",
       "      <th>word_idf_intersection</th>\n",
       "      <th>paragraph_lemmatized</th>\n",
       "      <th>question_lemmatized</th>\n",
       "      <th>word2vec_similarity_max</th>\n",
       "      <th>word2vec_similarity_min</th>\n",
       "      <th>word2vec_similarity_mean</th>\n",
       "      <th>word2vec_similarity_std</th>\n",
       "      <th>len_intersection_w2v</th>\n",
       "      <th>idf_intersection_w2v</th>\n",
       "      <th>relative_intersection_len_w2v</th>\n",
       "      <th>relative_intersection_question_len_w2v</th>\n",
       "      <th>relative_intersection_idf_w2v</th>\n",
       "      <th>relative_intersection_question_idf_w2v</th>\n",
       "      <th>word_idf_intersection_w2v</th>\n",
       "      <th>word_mover_distance</th>\n",
       "      <th>word_mover_distance_lemm</th>\n",
       "      <th>word_mover_sentence_distance_mean</th>\n",
       "      <th>word_mover_sentence_distance_std</th>\n",
       "      <th>word_mover_sentence_distance_max</th>\n",
       "      <th>word_mover_sentence_distance_min</th>\n",
       "      <th>word_mover_sentence_distance_split_max</th>\n",
       "      <th>word_mover_sentence_distance_split_min</th>\n",
       "      <th>word_mover_sentence_distance_split_mean</th>\n",
       "      <th>word_mover_sentence_distance_split_std</th>\n",
       "      <th>word_mover_sentence_distance_split_lemm_max</th>\n",
       "      <th>word_mover_sentence_distance_split_lemm_min</th>\n",
       "      <th>word_mover_sentence_distance_split_lemm_mean</th>\n",
       "      <th>word_mover_sentence_distance_split_lemm_std</th>\n",
       "      <th>answer</th>\n",
       "      <th>...</th>\n",
       "      <th>question_residuals_len_relative_prediction_sentence</th>\n",
       "      <th>question_residuals_idf</th>\n",
       "      <th>question_residuals_idf_relative_question</th>\n",
       "      <th>question_residuals_idf_relative_prediction_sentence</th>\n",
       "      <th>overlap</th>\n",
       "      <th>len_overlap_relative_paragraph_max</th>\n",
       "      <th>len_overlap_relative_question_max</th>\n",
       "      <th>idf_overlap_max</th>\n",
       "      <th>len_overlap_relative_paragraph_mean</th>\n",
       "      <th>len_overlap_relative_question_mean</th>\n",
       "      <th>idf_overlap_mean</th>\n",
       "      <th>len_overlap_relative_paragraph_std</th>\n",
       "      <th>len_overlap_relative_question_std</th>\n",
       "      <th>idf_overlap_std</th>\n",
       "      <th>similarity_tfid</th>\n",
       "      <th>word_mover_distance_prediction</th>\n",
       "      <th>similarity_prediction_tfid</th>\n",
       "      <th>similarity_tfid_split_max</th>\n",
       "      <th>similarity_tfid_split_min</th>\n",
       "      <th>similarity_tfid_split_mean</th>\n",
       "      <th>similarity_tfid_split_std</th>\n",
       "      <th>unique_words_relative_to_question</th>\n",
       "      <th>word_ocurences_mean</th>\n",
       "      <th>word_ocurences_std</th>\n",
       "      <th>word_ocurences_max</th>\n",
       "      <th>word_ocurences_max_relative_to_question</th>\n",
       "      <th>misspelling</th>\n",
       "      <th>uncategorized</th>\n",
       "      <th>whitespace</th>\n",
       "      <th>typographical</th>\n",
       "      <th>duplication</th>\n",
       "      <th>target_1</th>\n",
       "      <th>similarity_pattern_mean</th>\n",
       "      <th>similarity_pattern_std</th>\n",
       "      <th>similarity_pattern_max</th>\n",
       "      <th>similarity_pattern_min</th>\n",
       "      <th>word_mover_distance_residuals</th>\n",
       "      <th>similarity_residuals_tfid</th>\n",
       "      <th>word_mover_distance_residuals_prediction</th>\n",
       "      <th>question_words_in_paragraph_relative</th>\n",
       "      <th>similarity_all_mean</th>\n",
       "      <th>similarity_tfid_relative_split</th>\n",
       "      <th>similarity_tfid_relative_pattern</th>\n",
       "      <th>word_mover_distance_all_mean</th>\n",
       "      <th>word_mover_distance_all_mean_all</th>\n",
       "      <th>word_mover_distance_relative_sentence</th>\n",
       "      <th>word_mover_distance_relative_sentence_split</th>\n",
       "      <th>word_mover_distance_residuals_relative_paragraph</th>\n",
       "      <th>question_words_in_prediction_sentence_words_relative</th>\n",
       "      <th>question_words_count_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1480469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Точное место погребения Моцарта доподлинно неизвестно: в его времена могилы оставались необозначенными, надгробные камни разрешалось ставить не на месте самого захоронения, а у стены кладбища. Могилу Моцарта много лет подряд навещала супруга его друга Иоганна Георга Альбрехтсбергера, которая брала с собой сына. Он точно помнил место захоронения композитора и, когда, по случаю пятидесятилетия со дня смерти Моцарта, стали разыскивать его захоронение, смог его показать. В 1859 году там соорудили памятник по проекту фон Гассера — знаменитого Плачущего Ангела. В связи со столетием со дня смерти композитора памятник перенесли в музыкальный уголок Центрального кладбища Вены, из-за чего снова возникла опасность потерять настоящую могилу. Тогда надзиратель кладбища Святого Марка Александр Кругер из различных остатков прежних надгробий соорудил маленький памятник. В настоящее время, Плачущий Ангел возвращён на своё прежнее место.</td>\n",
       "      <td>1520</td>\n",
       "      <td>Кого брала с Точное не навещала супруга ?</td>\n",
       "      <td>140847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.650145</td>\n",
       "      <td>761.173083</td>\n",
       "      <td>44.633552</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.881213</td>\n",
       "      <td>7.318972</td>\n",
       "      <td>7.235735</td>\n",
       "      <td>7.438925</td>\n",
       "      <td>точный место погребение моцарт доподлинно неизвестно время могила оставаться необозначенный надгробный камень разрешаться ставить место самый захоронение стена кладбище могила моцарт год подряд навещать супруг друг иоганн георг альбрехтсбергер который брать себя сын точно помнить место захоронение композитор случай пятидесятилетие день смерть моцарт стать разыскивать захоронение смочь показать 1859 год соорудить памятник проект фон гассера знаменитый плачущий ангел связь столетие день смерть композитор памятник перенести музыкальный уголок центральный кладбище вена изз снова возникнуть опасность потерять настоящий могила надзиратель кладбище святой марка александр кругера различный остаток прежний надгробие соорудить маленький памятник настоящее время плачущий ангел возвратить свой прежний место</td>\n",
       "      <td>кто брать точный навещать супруг</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>185.5</td>\n",
       "      <td>799.294874</td>\n",
       "      <td>1.783654</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>1.050083</td>\n",
       "      <td>15.780702</td>\n",
       "      <td>133.215812</td>\n",
       "      <td>0.457344</td>\n",
       "      <td>0.497774</td>\n",
       "      <td>0.474622</td>\n",
       "      <td>0.118511</td>\n",
       "      <td>0.615088</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>1.063750</td>\n",
       "      <td>0.562488</td>\n",
       "      <td>0.876769</td>\n",
       "      <td>0.188471</td>\n",
       "      <td>1.315026</td>\n",
       "      <td>0.557647</td>\n",
       "      <td>0.876861</td>\n",
       "      <td>0.301806</td>\n",
       "      <td>Могилу Моцарта много лет подряд его друга Иоганна Георга Альбрехтсбергера, которая собой сына.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>18.220555</td>\n",
       "      <td>0.359734</td>\n",
       "      <td>0.172884</td>\n",
       "      <td>с брала навещала супруга</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>32.429590</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>6.213445</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>11.363185</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.850462e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988049</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>9.286642</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.671399</td>\n",
       "      <td>0.768286</td>\n",
       "      <td>0.963597</td>\n",
       "      <td>0.521625</td>\n",
       "      <td>0.947394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.</td>\n",
       "      <td>1009</td>\n",
       "      <td>Что оставалось неизвестными различие между различие между механизмы наследственности ?</td>\n",
       "      <td>140848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.677522</td>\n",
       "      <td>971.654247</td>\n",
       "      <td>35.956109</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.048039</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.770309</td>\n",
       "      <td>6.990318</td>\n",
       "      <td>6.668217</td>\n",
       "      <td>7.191222</td>\n",
       "      <td>точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор</td>\n",
       "      <td>оставаться неизвестный различие различие механизм наследственность</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.570092e-16</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>5103.569765</td>\n",
       "      <td>8.755396</td>\n",
       "      <td>173.857143</td>\n",
       "      <td>5.252455</td>\n",
       "      <td>109.336775</td>\n",
       "      <td>1020.713953</td>\n",
       "      <td>0.317910</td>\n",
       "      <td>0.408551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283208</td>\n",
       "      <td>0.608992</td>\n",
       "      <td>0.492117</td>\n",
       "      <td>0.534042</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.696897</td>\n",
       "      <td>0.389744</td>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.134993</td>\n",
       "      <td>Точные и появления новых черт оставались неизвестными.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>42.869749</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>механизмы неизвестными наследственности</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>24.740889</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.010659</td>\n",
       "      <td>5.405925</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>8.088969</td>\n",
       "      <td>0.139036</td>\n",
       "      <td>0.311169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121105</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>0.081352</td>\n",
       "      <td>0.040582</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.774896</td>\n",
       "      <td>3.183454e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.324688</td>\n",
       "      <td>0.348497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345288</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.331761</td>\n",
       "      <td>1.709064</td>\n",
       "      <td>0.179425</td>\n",
       "      <td>0.339981</td>\n",
       "      <td>0.342285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595290</td>\n",
       "      <td>1.009293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.</td>\n",
       "      <td>1009</td>\n",
       "      <td>Кто отметил отметил механизмы причин временного разногласия между зарождающейся генетикой механизмы ?</td>\n",
       "      <td>140849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.466007</td>\n",
       "      <td>971.654247</td>\n",
       "      <td>61.816922</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>0.063620</td>\n",
       "      <td>0.958907</td>\n",
       "      <td>6.990318</td>\n",
       "      <td>7.162890</td>\n",
       "      <td>7.727115</td>\n",
       "      <td>точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор</td>\n",
       "      <td>отметить отметить механизм причина временной разногласие зарождаться генетика механизм</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.157397e-01</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>4198.296311</td>\n",
       "      <td>7.316547</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>4.320772</td>\n",
       "      <td>65.124188</td>\n",
       "      <td>524.787039</td>\n",
       "      <td>0.191377</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.560621</td>\n",
       "      <td>0.330985</td>\n",
       "      <td>0.444836</td>\n",
       "      <td>0.083972</td>\n",
       "      <td>1.276059</td>\n",
       "      <td>0.296215</td>\n",
       "      <td>0.644299</td>\n",
       "      <td>0.374565</td>\n",
       "      <td>Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из и дарвинизмом.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>30.635832</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0.248206</td>\n",
       "      <td>зарождающейся разногласия между временного причин генетикой</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>47.823548</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>5.454526</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.016727</td>\n",
       "      <td>13.198798</td>\n",
       "      <td>0.173734</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052963</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.503743</td>\n",
       "      <td>2.873525e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305878</td>\n",
       "      <td>0.380296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360630</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.243480</td>\n",
       "      <td>3.280287</td>\n",
       "      <td>0.344886</td>\n",
       "      <td>0.320128</td>\n",
       "      <td>0.336906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430220</td>\n",
       "      <td>1.054534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.</td>\n",
       "      <td>1009</td>\n",
       "      <td>В каком году стала одной из Точные механизмы Точные механизмы ?</td>\n",
       "      <td>140850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.944643</td>\n",
       "      <td>971.654247</td>\n",
       "      <td>34.261465</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>6.990318</td>\n",
       "      <td>4.618080</td>\n",
       "      <td>4.894495</td>\n",
       "      <td>точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор</td>\n",
       "      <td>какой год стать один точный механизм точный механизм</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.330127e-01</td>\n",
       "      <td>575.5</td>\n",
       "      <td>2456.072256</td>\n",
       "      <td>4.140288</td>\n",
       "      <td>71.937500</td>\n",
       "      <td>2.527722</td>\n",
       "      <td>66.479795</td>\n",
       "      <td>350.867465</td>\n",
       "      <td>0.324486</td>\n",
       "      <td>0.329308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179404</td>\n",
       "      <td>0.698065</td>\n",
       "      <td>0.492903</td>\n",
       "      <td>0.588498</td>\n",
       "      <td>0.091218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая причин временного разногласия между зарождающейся генетикой и дарвинизмом.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>42.098557</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.341075</td>\n",
       "      <td>механизмы точные</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>15.118303</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>2.824081</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>5.039018</td>\n",
       "      <td>0.076656</td>\n",
       "      <td>0.327325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.714852</td>\n",
       "      <td>3.497819e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.256180</td>\n",
       "      <td>0.356265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393343</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.268912</td>\n",
       "      <td>5.033848</td>\n",
       "      <td>0.107233</td>\n",
       "      <td>0.228246</td>\n",
       "      <td>0.277099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551381</td>\n",
       "      <td>0.905735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.</td>\n",
       "      <td>1009</td>\n",
       "      <td>Кто развивал временную обусловлена каком году Грегор Мендель ?</td>\n",
       "      <td>140851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.632924</td>\n",
       "      <td>971.654247</td>\n",
       "      <td>47.300662</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.054168</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.898690</td>\n",
       "      <td>6.990318</td>\n",
       "      <td>6.579116</td>\n",
       "      <td>7.883444</td>\n",
       "      <td>точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор</td>\n",
       "      <td>развивать временной обусловить какой год грегор мендель</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>4.517540e-01</td>\n",
       "      <td>580.0</td>\n",
       "      <td>2484.482426</td>\n",
       "      <td>4.172662</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.556961</td>\n",
       "      <td>47.203959</td>\n",
       "      <td>414.080404</td>\n",
       "      <td>0.492936</td>\n",
       "      <td>0.353809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>В 1865 открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>29.549903</td>\n",
       "      <td>0.561434</td>\n",
       "      <td>0.316894</td>\n",
       "      <td>временную развивал</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>16.609958</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>2.872438</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>5.030900</td>\n",
       "      <td>0.140804</td>\n",
       "      <td>0.244754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.818846</td>\n",
       "      <td>3.137676e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275385</td>\n",
       "      <td>0.473170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306815</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.332323</td>\n",
       "      <td>3.773079</td>\n",
       "      <td>0.171954</td>\n",
       "      <td>0.123234</td>\n",
       "      <td>0.212153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.542199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         generated_p_3  generated_p_6  \\\n",
       "1480469            0.0            1.0   \n",
       "1480470            0.0            1.0   \n",
       "1480471            0.0            1.0   \n",
       "1480472            0.0            1.0   \n",
       "1480473            0.0            1.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                paragraph  \\\n",
       "1480469                                                                                                                                                                                                                                                                                                                                                                                                             Точное место погребения Моцарта доподлинно неизвестно: в его времена могилы оставались необозначенными, надгробные камни разрешалось ставить не на месте самого захоронения, а у стены кладбища. Могилу Моцарта много лет подряд навещала супруга его друга Иоганна Георга Альбрехтсбергера, которая брала с собой сына. Он точно помнил место захоронения композитора и, когда, по случаю пятидесятилетия со дня смерти Моцарта, стали разыскивать его захоронение, смог его показать. В 1859 году там соорудили памятник по проекту фон Гассера — знаменитого Плачущего Ангела. В связи со столетием со дня смерти композитора памятник перенесли в музыкальный уголок Центрального кладбища Вены, из-за чего снова возникла опасность потерять настоящую могилу. Тогда надзиратель кладбища Святого Марка Александр Кругер из различных остатков прежних надгробий соорудил маленький памятник. В настоящее время, Плачущий Ангел возвращён на своё прежнее место.   \n",
       "1480470  Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.   \n",
       "1480471  Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.   \n",
       "1480472  Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.   \n",
       "1480473  Точные механизмы наследственности и появления новых черт оставались неизвестными. С целью объяснения этих механизмов Дарвин развивал временную теорию пангенезиса . В 1865 году Грегор Мендель открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года. Август Вейсманн отметил важное различие между зародышевыми (половыми) и соматическими клетками, а также то, что наследственность обусловлена только зародышевой линией клеток. Хуго де Фриз соединил дарвиновскую теорию пангенезиса с вейсманновскими представлениями о половых и соматических клетках и предположил, что пангены расположены в ядре клетки и могут перемещаться в цитоплазму и изменять структуру клетки. Де Фриз был также одним из учёных, которые сделали работу Менделя известной. Он полагал, что менделевские наследственные черты соответствуют передаче наследственных изменений по зародышевому пути. Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из причин временного разногласия между зарождающейся генетикой и дарвинизмом. Работы пионеров популяционной генетики, таких как Дж. Б. С. Холдейн, Сьюэл Райт, Рональд Фишер, ставят исследования эволюции на статистическую основу и, таким образом, устраняют это ложное противопоставление генетики и эволюции путём естественного отбора.   \n",
       "\n",
       "         paragraph_id  \\\n",
       "1480469          1520   \n",
       "1480470          1009   \n",
       "1480471          1009   \n",
       "1480472          1009   \n",
       "1480473          1009   \n",
       "\n",
       "                                                                                                      question  \\\n",
       "1480469                                                              Кого брала с Точное не навещала супруга ?   \n",
       "1480470                 Что оставалось неизвестными различие между различие между механизмы наследственности ?   \n",
       "1480471  Кто отметил отметил механизмы причин временного разногласия между зарождающейся генетикой механизмы ?   \n",
       "1480472                                        В каком году стала одной из Точные механизмы Точные механизмы ?   \n",
       "1480473                                         Кто развивал временную обусловлена каком году Грегор Мендель ?   \n",
       "\n",
       "         question_id  target  len_paragraph  len_question  len_intersection  \\\n",
       "1480469     140847.0     0.0          104.0           7.0               6.0   \n",
       "1480470     140848.0     0.0          139.0           7.0               5.0   \n",
       "1480471     140849.0     0.0          139.0           9.0               8.0   \n",
       "1480472     140850.0     0.0          139.0           8.0               7.0   \n",
       "1480473     140851.0     0.0          139.0           8.0               6.0   \n",
       "\n",
       "         idf_question  idf_paragraph  idf_intersection  relative_question_len  \\\n",
       "1480469     50.650145     761.173083         44.633552               0.067308   \n",
       "1480470     46.677522     971.654247         35.956109               0.050360   \n",
       "1480471     64.466007     971.654247         61.816922               0.064748   \n",
       "1480472     36.944643     971.654247         34.261465               0.057554   \n",
       "1480473     52.632924     971.654247         47.300662               0.057554   \n",
       "\n",
       "         relative_intersection_len  relative_intersection_question_len  \\\n",
       "1480469                   0.057692                            0.857143   \n",
       "1480470                   0.035971                            0.714286   \n",
       "1480471                   0.057554                            0.888889   \n",
       "1480472                   0.050360                            0.875000   \n",
       "1480473                   0.043165                            0.750000   \n",
       "\n",
       "         relative_question_idf  relative_intersection_idf  \\\n",
       "1480469               0.066542                   0.058638   \n",
       "1480470               0.048039                   0.037005   \n",
       "1480471               0.066347                   0.063620   \n",
       "1480472               0.038022                   0.035261   \n",
       "1480473               0.054168                   0.048681   \n",
       "\n",
       "         relative_intersection_question_idf  word_idf_paragraph  \\\n",
       "1480469                            0.881213            7.318972   \n",
       "1480470                            0.770309            6.990318   \n",
       "1480471                            0.958907            6.990318   \n",
       "1480472                            0.927373            6.990318   \n",
       "1480473                            0.898690            6.990318   \n",
       "\n",
       "         word_idf_question  word_idf_intersection  \\\n",
       "1480469           7.235735               7.438925   \n",
       "1480470           6.668217               7.191222   \n",
       "1480471           7.162890               7.727115   \n",
       "1480472           4.618080               4.894495   \n",
       "1480473           6.579116               7.883444   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        paragraph_lemmatized  \\\n",
       "1480469                                                                                                                                                                                                                                                                                                                                                                               точный место погребение моцарт доподлинно неизвестно время могила оставаться необозначенный надгробный камень разрешаться ставить место самый захоронение стена кладбище могила моцарт год подряд навещать супруг друг иоганн георг альбрехтсбергер который брать себя сын точно помнить место захоронение композитор случай пятидесятилетие день смерть моцарт стать разыскивать захоронение смочь показать 1859 год соорудить памятник проект фон гассера знаменитый плачущий ангел связь столетие день смерть композитор памятник перенести музыкальный уголок центральный кладбище вена изз снова возникнуть опасность потерять настоящий могила надзиратель кладбище святой марка александр кругера различный остаток прежний надгробие соорудить маленький памятник настоящее время плачущий ангел возвратить свой прежний место   \n",
       "1480470  точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор   \n",
       "1480471  точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор   \n",
       "1480472  точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор   \n",
       "1480473  точный механизм наследственность появление новый черта оставаться неизвестный цель объяснение этот механизм дарвин развивать временной теория пангенезис 1865 год грегор мендель открыть закон наследственность однако работа оставаться практически неизвестный 1900 год август вейсманна отметить важный различие зародышевый половый соматический клетка также наследственность обусловить зародышевый линия клетка хуго де фриз соединить дарвиновский теория пангенезис вейсманновский представление половый соматический клетка предположить панген расположить ядро клетка мочь перемещаться цитоплазма изменять структура клетка де фриз также один учёный который сделать работа менделить известный полагать менделевский наследственный черта соответствовать передача наследственный изменение зародышевый путь объяснить возникновение новый черта де фриз развивать теория мутация который стать один причина временной разногласие зарождаться генетика дарвинизм работа пионер популяционный генетик такой дж б холдейн сьюэла райт рональд фишер ставить исследование эволюция статистический основа такой образ устранять это ложный противопоставление генетик эволюция путём естественный отбор   \n",
       "\n",
       "                                                                            question_lemmatized  \\\n",
       "1480469                                                        кто брать точный навещать супруг   \n",
       "1480470                      оставаться неизвестный различие различие механизм наследственность   \n",
       "1480471  отметить отметить механизм причина временной разногласие зарождаться генетика механизм   \n",
       "1480472                                    какой год стать один точный механизм точный механизм   \n",
       "1480473                                 развивать временной обусловить какой год грегор мендель   \n",
       "\n",
       "         word2vec_similarity_max  word2vec_similarity_min  \\\n",
       "1480469                      1.0                      0.0   \n",
       "1480470                      1.0                      1.0   \n",
       "1480471                      1.0                      0.0   \n",
       "1480472                      1.0                      0.0   \n",
       "1480473                      1.0                      0.0   \n",
       "\n",
       "         word2vec_similarity_mean  word2vec_similarity_std  \\\n",
       "1480469                  0.800000             4.000000e-01   \n",
       "1480470                  1.000000             1.570092e-16   \n",
       "1480471                  0.777778             4.157397e-01   \n",
       "1480472                  0.750000             4.330127e-01   \n",
       "1480473                  0.714286             4.517540e-01   \n",
       "\n",
       "         len_intersection_w2v  idf_intersection_w2v  \\\n",
       "1480469                 185.5            799.294874   \n",
       "1480470                1217.0           5103.569765   \n",
       "1480471                1017.0           4198.296311   \n",
       "1480472                 575.5           2456.072256   \n",
       "1480473                 580.0           2484.482426   \n",
       "\n",
       "         relative_intersection_len_w2v  \\\n",
       "1480469                       1.783654   \n",
       "1480470                       8.755396   \n",
       "1480471                       7.316547   \n",
       "1480472                       4.140288   \n",
       "1480473                       4.172662   \n",
       "\n",
       "         relative_intersection_question_len_w2v  \\\n",
       "1480469                               26.500000   \n",
       "1480470                              173.857143   \n",
       "1480471                              113.000000   \n",
       "1480472                               71.937500   \n",
       "1480473                               72.500000   \n",
       "\n",
       "         relative_intersection_idf_w2v  \\\n",
       "1480469                       1.050083   \n",
       "1480470                       5.252455   \n",
       "1480471                       4.320772   \n",
       "1480472                       2.527722   \n",
       "1480473                       2.556961   \n",
       "\n",
       "         relative_intersection_question_idf_w2v  word_idf_intersection_w2v  \\\n",
       "1480469                               15.780702                 133.215812   \n",
       "1480470                              109.336775                1020.713953   \n",
       "1480471                               65.124188                 524.787039   \n",
       "1480472                               66.479795                 350.867465   \n",
       "1480473                               47.203959                 414.080404   \n",
       "\n",
       "         word_mover_distance  word_mover_distance_lemm  \\\n",
       "1480469             0.457344                  0.497774   \n",
       "1480470             0.317910                  0.408551   \n",
       "1480471             0.191377                  0.312340   \n",
       "1480472             0.324486                  0.329308   \n",
       "1480473             0.492936                  0.353809   \n",
       "\n",
       "         word_mover_sentence_distance_mean  word_mover_sentence_distance_std  \\\n",
       "1480469                           0.474622                          0.118511   \n",
       "1480470                           0.000000                          0.000000   \n",
       "1480471                           0.000000                          0.000000   \n",
       "1480472                           0.000000                          0.000000   \n",
       "1480473                           0.000000                          0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_max  word_mover_sentence_distance_min  \\\n",
       "1480469                          0.615088                          0.240196   \n",
       "1480470                          0.000000                          0.283208   \n",
       "1480471                          0.000000                          0.096105   \n",
       "1480472                          0.000000                          0.179404   \n",
       "1480473                          0.000000                          0.244754   \n",
       "\n",
       "         word_mover_sentence_distance_split_max  \\\n",
       "1480469                                1.063750   \n",
       "1480470                                0.608992   \n",
       "1480471                                0.560621   \n",
       "1480472                                0.698065   \n",
       "1480473                                0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_split_min  \\\n",
       "1480469                                0.562488   \n",
       "1480470                                0.492117   \n",
       "1480471                                0.330985   \n",
       "1480472                                0.492903   \n",
       "1480473                                0.482496   \n",
       "\n",
       "         word_mover_sentence_distance_split_mean  \\\n",
       "1480469                                 0.876769   \n",
       "1480470                                 0.534042   \n",
       "1480471                                 0.444836   \n",
       "1480472                                 0.588498   \n",
       "1480473                                 0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_split_std  \\\n",
       "1480469                                0.188471   \n",
       "1480470                                0.053122   \n",
       "1480471                                0.083972   \n",
       "1480472                                0.091218   \n",
       "1480473                                0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_split_lemm_max  \\\n",
       "1480469                                     1.315026   \n",
       "1480470                                     0.696897   \n",
       "1480471                                     1.276059   \n",
       "1480472                                     0.000000   \n",
       "1480473                                     0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_split_lemm_min  \\\n",
       "1480469                                     0.557647   \n",
       "1480470                                     0.389744   \n",
       "1480471                                     0.296215   \n",
       "1480472                                     0.522769   \n",
       "1480473                                     0.437272   \n",
       "\n",
       "         word_mover_sentence_distance_split_lemm_mean  \\\n",
       "1480469                                      0.876861   \n",
       "1480470                                      0.507971   \n",
       "1480471                                      0.644299   \n",
       "1480472                                      0.000000   \n",
       "1480473                                      0.000000   \n",
       "\n",
       "         word_mover_sentence_distance_split_lemm_std  \\\n",
       "1480469                                     0.301806   \n",
       "1480470                                     0.134993   \n",
       "1480471                                     0.374565   \n",
       "1480472                                     0.000000   \n",
       "1480473                                     0.000000   \n",
       "\n",
       "                                                                                                                                                                answer  \\\n",
       "1480469                                                                 Могилу Моцарта много лет подряд его друга Иоганна Георга Альбрехтсбергера, которая собой сына.   \n",
       "1480470                                                                                                         Точные и появления новых черт оставались неизвестными.   \n",
       "1480471                                               Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая стала одной из и дарвинизмом.   \n",
       "1480472  Чтобы объяснить возникновение новых черт, де Фриз развивал теорию мутаций, которая причин временного разногласия между зарождающейся генетикой и дарвинизмом.   \n",
       "1480473                                                     В 1865 открыл законы наследственности, однако его работы оставались практически неизвестными до 1900 года.   \n",
       "\n",
       "                     ...                \\\n",
       "1480469              ...                 \n",
       "1480470              ...                 \n",
       "1480471              ...                 \n",
       "1480472              ...                 \n",
       "1480473              ...                 \n",
       "\n",
       "        question_residuals_len_relative_prediction_sentence  \\\n",
       "1480469                                            0.033613   \n",
       "1480470                                            0.098765   \n",
       "1480471                                            0.034884   \n",
       "1480472                                            0.046512   \n",
       "1480473                                            0.047619   \n",
       "\n",
       "         question_residuals_idf  question_residuals_idf_relative_question  \\\n",
       "1480469               18.220555                                  0.359734   \n",
       "1480470               42.869749                                  0.740503   \n",
       "1480471               30.635832                                  0.390467   \n",
       "1480472               42.098557                                  0.771196   \n",
       "1480473               29.549903                                  0.561434   \n",
       "\n",
       "         question_residuals_idf_relative_prediction_sentence  \\\n",
       "1480469                                             0.172884   \n",
       "1480470                                             0.813749   \n",
       "1480471                                             0.248206   \n",
       "1480472                                             0.341075   \n",
       "1480473                                             0.316894   \n",
       "\n",
       "                                                             overlap  \\\n",
       "1480469                                     с брала навещала супруга   \n",
       "1480470                      механизмы неизвестными наследственности   \n",
       "1480471  зарождающейся разногласия между временного причин генетикой   \n",
       "1480472                                             механизмы точные   \n",
       "1480473                                           временную развивал   \n",
       "\n",
       "         len_overlap_relative_paragraph_max  \\\n",
       "1480469                            0.004287   \n",
       "1480470                            0.002259   \n",
       "1480471                            0.004518   \n",
       "1480472                            0.002259   \n",
       "1480473                            0.002259   \n",
       "\n",
       "         len_overlap_relative_question_max idf_overlap_max  \\\n",
       "1480469                           0.097561       32.429590   \n",
       "1480470                           0.034884       24.740889   \n",
       "1480471                           0.059406       47.823548   \n",
       "1480472                           0.047619       15.118303   \n",
       "1480473                           0.048387       16.609958   \n",
       "\n",
       "         len_overlap_relative_paragraph_mean  \\\n",
       "1480469                             0.000919   \n",
       "1480470                             0.000690   \n",
       "1480471                             0.000565   \n",
       "1480472                             0.000565   \n",
       "1480473                             0.000439   \n",
       "\n",
       "         len_overlap_relative_question_mean  idf_overlap_mean  \\\n",
       "1480469                            0.020906          6.213445   \n",
       "1480470                            0.010659          5.405925   \n",
       "1480471                            0.007426          5.454526   \n",
       "1480472                            0.011905          2.824081   \n",
       "1480473                            0.009409          2.872438   \n",
       "\n",
       "         len_overlap_relative_paragraph_std  \\\n",
       "1480469                            0.001561   \n",
       "1480470                            0.000840   \n",
       "1480471                            0.001272   \n",
       "1480472                            0.000761   \n",
       "1480473                            0.000718   \n",
       "\n",
       "         len_overlap_relative_question_std  idf_overlap_std similarity_tfid  \\\n",
       "1480469                           0.035533        11.363185        0.093616   \n",
       "1480470                           0.012964         8.088969        0.139036   \n",
       "1480471                           0.016727        13.198798        0.173734   \n",
       "1480472                           0.016038         5.039018        0.076656   \n",
       "1480473                           0.015384         5.030900        0.140804   \n",
       "\n",
       "         word_mover_distance_prediction  similarity_prediction_tfid  \\\n",
       "1480469                        0.240196                         0.0   \n",
       "1480470                        0.311169                         0.0   \n",
       "1480471                        0.096105                         0.0   \n",
       "1480472                        0.327325                         0.0   \n",
       "1480473                        0.244754                         0.0   \n",
       "\n",
       "         similarity_tfid_split_max  similarity_tfid_split_min  \\\n",
       "1480469                   0.020591                   0.000000   \n",
       "1480470                   0.121105                   0.025628   \n",
       "1480471                   0.089503                   0.000000   \n",
       "1480472                   0.032413                   0.000000   \n",
       "1480473                   0.073566                   0.000000   \n",
       "\n",
       "         similarity_tfid_split_mean  similarity_tfid_split_std  \\\n",
       "1480469                    0.010081                   0.010085   \n",
       "1480470                    0.081352                   0.040582   \n",
       "1480471                    0.052963                   0.035561   \n",
       "1480472                    0.015228                   0.011794   \n",
       "1480473                    0.037318                   0.026589   \n",
       "\n",
       "         unique_words_relative_to_question  word_ocurences_mean  \\\n",
       "1480469                           2.714286             1.000000   \n",
       "1480470                           2.857143             1.333333   \n",
       "1480471                           2.555556             1.444444   \n",
       "1480472                           2.250000             1.500000   \n",
       "1480473                           2.500000             1.000000   \n",
       "\n",
       "         word_ocurences_std  word_ocurences_max  \\\n",
       "1480469            0.000000                 1.0   \n",
       "1480470            0.471405                 2.0   \n",
       "1480471            0.496904                 2.0   \n",
       "1480472            0.500000                 2.0   \n",
       "1480473            0.000000                 1.0   \n",
       "\n",
       "         word_ocurences_max_relative_to_question  misspelling  uncategorized  \\\n",
       "1480469                                 0.142857          0.0            0.0   \n",
       "1480470                                 0.285714          0.0            0.0   \n",
       "1480471                                 0.222222          0.0            0.0   \n",
       "1480472                                 0.250000          0.0            0.0   \n",
       "1480473                                 0.125000          0.0            0.0   \n",
       "\n",
       "         whitespace  typographical  duplication  target_1  \\\n",
       "1480469         0.0            0.0          0.0       3.0   \n",
       "1480470         0.0            0.0          0.0       3.0   \n",
       "1480471         0.0            0.0          0.0       3.0   \n",
       "1480472         0.0            0.0          0.0       3.0   \n",
       "1480473         0.0            0.0          0.0       3.0   \n",
       "\n",
       "         similarity_pattern_mean  similarity_pattern_std  \\\n",
       "1480469                 1.000000            7.850462e-17   \n",
       "1480470                 0.774896            3.183454e-01   \n",
       "1480471                 0.503743            2.873525e-01   \n",
       "1480472                 0.714852            3.497819e-01   \n",
       "1480473                 0.818846            3.137676e-01   \n",
       "\n",
       "         similarity_pattern_max  similarity_pattern_min  \\\n",
       "1480469                     1.0                1.000000   \n",
       "1480470                     1.0                0.324688   \n",
       "1480471                     1.0                0.305878   \n",
       "1480472                     1.0                0.256180   \n",
       "1480473                     1.0                0.275385   \n",
       "\n",
       "         word_mover_distance_residuals  similarity_residuals_tfid  \\\n",
       "1480469                       0.936072                        0.0   \n",
       "1480470                       0.348497                        0.0   \n",
       "1480471                       0.380296                        0.0   \n",
       "1480472                       0.356265                        0.0   \n",
       "1480473                       0.473170                        0.0   \n",
       "\n",
       "         word_mover_distance_residuals_prediction  \\\n",
       "1480469                                  0.988049   \n",
       "1480470                                  0.345288   \n",
       "1480471                                  0.360630   \n",
       "1480472                                  0.393343   \n",
       "1480473                                  0.306815   \n",
       "\n",
       "         question_words_in_paragraph_relative  similarity_all_mean  \\\n",
       "1480469                              0.750000             0.367899   \n",
       "1480470                              0.900000             0.331761   \n",
       "1480471                              0.916667             0.243480   \n",
       "1480472                              0.909091             0.268912   \n",
       "1480473                              0.777778             0.332323   \n",
       "\n",
       "         similarity_tfid_relative_split  similarity_tfid_relative_pattern  \\\n",
       "1480469                        9.286642                          0.093616   \n",
       "1480470                        1.709064                          0.179425   \n",
       "1480471                        3.280287                          0.344886   \n",
       "1480472                        5.033848                          0.107233   \n",
       "1480473                        3.773079                          0.171954   \n",
       "\n",
       "         word_mover_distance_all_mean  word_mover_distance_all_mean_all  \\\n",
       "1480469                      0.671399                          0.768286   \n",
       "1480470                      0.339981                          0.342285   \n",
       "1480471                      0.320128                          0.336906   \n",
       "1480472                      0.228246                          0.277099   \n",
       "1480473                      0.123234                          0.212153   \n",
       "\n",
       "         word_mover_distance_relative_sentence  \\\n",
       "1480469                               0.963597   \n",
       "1480470                               0.000000   \n",
       "1480471                               0.000000   \n",
       "1480472                               0.000000   \n",
       "1480473                               0.000000   \n",
       "\n",
       "         word_mover_distance_relative_sentence_split  \\\n",
       "1480469                                     0.521625   \n",
       "1480470                                     0.595290   \n",
       "1480471                                     0.430220   \n",
       "1480472                                     0.551381   \n",
       "1480473                                     0.000000   \n",
       "\n",
       "         word_mover_distance_residuals_relative_paragraph  \\\n",
       "1480469                                          0.947394   \n",
       "1480470                                          1.009293   \n",
       "1480471                                          1.054534   \n",
       "1480472                                          0.905735   \n",
       "1480473                                          1.542199   \n",
       "\n",
       "         question_words_in_prediction_sentence_words_relative  \\\n",
       "1480469                                                   NaN   \n",
       "1480470                                                   NaN   \n",
       "1480471                                                   NaN   \n",
       "1480472                                                   NaN   \n",
       "1480473                                                   NaN   \n",
       "\n",
       "         question_words_count_relative  \n",
       "1480469                       0.205128  \n",
       "1480470                       0.205128  \n",
       "1480471                       0.205128  \n",
       "1480472                       0.205128  \n",
       "1480473                       0.205128  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "grammar for train:   0%|          | 0/159391 [00:00<?, ?it/s]\u001b[A\n",
      "grammar for train:   0%|          | 1/159391 [00:00<23:14:38,  1.90it/s]\u001b[A\n",
      "grammar for train:   0%|          | 106/159391 [00:00<16:16:22,  2.72it/s]\u001b[A\n",
      "grammar for train:   0%|          | 208/159391 [00:00<11:23:48,  3.88it/s]\u001b[A\n",
      "grammar for train:   0%|          | 311/159391 [00:00<7:59:07,  5.53it/s] \u001b[A\n",
      "grammar for train:   0%|          | 416/159391 [00:00<5:35:55,  7.89it/s]\u001b[A\n",
      "grammar for train:   0%|          | 513/159391 [00:01<3:55:49, 11.23it/s]\u001b[A\n",
      "grammar for train:   0%|          | 615/159391 [00:01<2:45:45, 15.96it/s]\u001b[A\n",
      "grammar for train:   0%|          | 722/159391 [00:01<1:56:42, 22.66it/s]\u001b[A\n",
      "grammar for train:   1%|          | 826/159391 [00:01<1:22:24, 32.07it/s]\u001b[A\n",
      "grammar for train:   1%|          | 930/159391 [00:01<58:24, 45.21it/s]  \u001b[A\n",
      "grammar for train:   1%|          | 1035/159391 [00:01<41:37, 63.42it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1138/159391 [00:01<29:53, 88.26it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1244/159391 [00:01<21:39, 121.73it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1351/159391 [00:01<15:53, 165.78it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1458/159391 [00:01<11:51, 221.98it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1565/159391 [00:02<09:02, 291.05it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1671/159391 [00:02<07:06, 370.02it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1779/159391 [00:02<05:42, 460.52it/s]\u001b[A\n",
      "grammar for train:   1%|          | 1886/159391 [00:02<04:43, 555.35it/s]\u001b[A\n",
      "grammar for train:   1%|▏         | 1994/159391 [00:02<04:02, 649.04it/s]\u001b[A\n",
      "grammar for train:   1%|▏         | 2101/159391 [00:02<03:33, 735.47it/s]\u001b[A\n",
      "grammar for train:   1%|▏         | 2211/159391 [00:02<03:12, 815.07it/s]\u001b[A\n",
      "grammar for train:   1%|▏         | 2319/159391 [00:02<03:02, 862.27it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2424/159391 [00:02<02:54, 898.60it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2528/159391 [00:02<02:48, 930.52it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2631/159391 [00:03<02:44, 951.77it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2734/159391 [00:03<02:42, 965.94it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2836/159391 [00:03<02:39, 979.15it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 2938/159391 [00:03<02:37, 990.99it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3042/159391 [00:03<02:35, 1002.87it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3147/159391 [00:03<02:34, 1013.48it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3254/159391 [00:03<02:31, 1028.47it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3362/159391 [00:03<02:29, 1041.86it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3468/159391 [00:03<02:29, 1046.27it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3576/159391 [00:03<02:27, 1054.28it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3683/159391 [00:04<02:27, 1056.68it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3790/159391 [00:04<02:26, 1059.55it/s]\u001b[A\n",
      "grammar for train:   2%|▏         | 3898/159391 [00:04<02:26, 1063.12it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4006/159391 [00:04<02:25, 1065.34it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4114/159391 [00:04<02:25, 1068.35it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4221/159391 [00:04<02:25, 1067.31it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4329/159391 [00:04<02:25, 1068.99it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4436/159391 [00:04<02:25, 1068.23it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4544/159391 [00:04<02:24, 1069.06it/s]\u001b[A\n",
      "grammar for train:   3%|▎         | 4652/159391 [00:04<02:24, 1070.91it/s]\u001b[A\n",
      "grammar for train: 100%|██████████| 159391/159391 [02:31<00:00, 1051.50it/s]\n",
      "grammar for test: 100%|██████████| 74286/74286 [00:57<00:00, 1283.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in [('train', dftrain), ('test', dftest)]:\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"grammar for \" + name):\n",
    "        \n",
    "        question_words = row.question.lower().strip('?').split(' ')\n",
    "        prediction_sentence_words = row.prediction_sentence.lower().replace('.', '').split(' ')\n",
    "        \n",
    "        count = 0\n",
    "        for word in question_words:\n",
    "            if word in prediction_sentence_words:\n",
    "                count += 1\n",
    "        \n",
    "        df.loc[index, 'question_words_in_prediction_sentence_words_relative'] = count / len(question_words)\n",
    "        \n",
    "    df.loc[:, 'question_words_count_relative'] = df['question_words_in_prediction_sentence_words_relative'] / df['question_words_in_paragraph_relative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftrain.to_csv('../../data/train_task1_latest_pred.csv', sep=';', index= False)\n",
    "dftest.to_csv('../../data/test_task1_latest_pred.csv', sep=';', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим даные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('../../data/train_task1_latest_pred.csv', sep=';')\n",
    "dftest = pd.read_csv('../../data/test_task1_latest_pred.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(dftrain.question_lemmatized.unique())\n",
    "df.columns = ['question_lemmatized']\n",
    "df['question_patterns'] = df['question_lemmatized'].map(lambda x: get_patterns(x.strip('?')))\n",
    "dftrain = dftrain.merge(df, on = 'question_lemmatized', how = 'left')\n",
    "\n",
    "df = pd.DataFrame(dftest.question_lemmatized.unique())\n",
    "df.columns = ['question_lemmatized']\n",
    "df['question_patterns'] = df['question_lemmatized'].map(lambda x: get_patterns(x.strip('?')))\n",
    "dftest = dftest.merge(df, on = 'question_lemmatized', how = 'left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "q_patterns = []\n",
    "for question_pattern in dftrain.question_patterns:\n",
    "    q_patterns = set(np.append(list(q_patterns), question_pattern))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "patterns_dictionary = {(v, k) for k,v in enumerate(list([x for x in q_patterns if x is not None]))}\n",
    "patterns_dictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### NLTK cfg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from nltk import CFG"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.word_tokenize?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "text = \"Что в творчестве сочетали многие панк-группы?\"\n",
    "text = nltk.word_tokenize(text.lower().translate(remove_punctuation_map))\n",
    "tagged_text = nltk.pos_tag(text, lang='rus')\n",
    "pos_tags = [pos for (token,pos) in nltk.pos_tag(text, lang='rus')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tagged_text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "' -> '.join(pos_tags)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "  CONJ -> PR\n",
    "  S -> V\n",
    "  V -> A-PRO=pl\n",
    "  A-PRO=pl -> S\n",
    "  S-PRO -> 'что'  \n",
    "  A-PRO=pl -> 'многие'\n",
    "  PR -> 'в'\n",
    "  S -> 'творчестве' | 'панкгруппы'\n",
    "  V -> 'сочетали'\n",
    "  \"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tree = parser.parse(text)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
